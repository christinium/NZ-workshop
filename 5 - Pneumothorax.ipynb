{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/christinium/AIMed_Workshop_2018/blob/master/MIT%20Tutorial%20-%20Part%20C%20-%20Pneumothorax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kahC0Hi6sX7a"
   },
   "source": [
    "# Pneumothorax example\n",
    "\n",
    "## Sentence tokenization, and spotting term + negation\n",
    "\n",
    "This example spots meantions of the \"pneumothorax\" lexicon in CXR reports and looks at whether the spotted pneumothorax mentioned was negated or not. \n",
    "\n",
    "*Joy Wu* <joy.wu@ibm.com>*, *Daniel Gruhl <dgruhl@us.ibm.com>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IghAvd9KsX7g"
   },
   "outputs": [],
   "source": [
    "# Required files\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "\n",
    "from google.colab import auth\n",
    "from google.cloud import bigquery\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eItuw11H61V2"
   },
   "source": [
    "**Authenticate:** The line of code below ensures you are an authenticated user accessing the MIMIC database. You will need to rerun this each time you open the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H30PHyTf2m0I"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user() #This will allow you to authenticate access to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRzpINxx7BJY"
   },
   "source": [
    "**Query Function: **This is a method that executes a desired SQL query on the database. If you want to run a query, you can use the function name below, which we named run_query()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7Y86QrA2xDy"
   },
   "outputs": [],
   "source": [
    "project_id='new-zealand-2018-datathon'\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"]=project_id\n",
    "# Read data from BigQuery into pandas dataframes.\n",
    "def run_query(query):\n",
    "  return pd.io.gbq.read_gbq(query, project_id=project_id, verbose=False, configuration={'query':{'useLegacySql': False}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72KosSwasX7p"
   },
   "source": [
    "### Sentence splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2oVmqJuLsX7s"
   },
   "outputs": [],
   "source": [
    "# Read the sample CXR reports into a pandas dataframe, and print out a random report\n",
    "#CXRreports = pd.read_csv('mimic3_1000cxrReports.csv')\n",
    "#CXRreports.head()\n",
    "\n",
    "\n",
    "CXRreports = run_query('''\n",
    "SELECT * \n",
    "FROM `hst-953-2018.NLP_workshop.cxr`\n",
    "''')\n",
    "CXRreports.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39aeASmGsX75"
   },
   "outputs": [],
   "source": [
    "#This prints a random report\n",
    "report = CXRreports.text[random.randint(0,1000)]\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XE_GBgB4f6w"
   },
   "outputs": [],
   "source": [
    "  #This imports nltk and punkt into our environment\n",
    "  >>> import nltk\n",
    "  >>> nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7iMxWsUsX8B"
   },
   "outputs": [],
   "source": [
    "# Tokenize the sentences with sent_tokenize from NLTK\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "# Alternatively, tokenize with PunktSentenceTokenizer from NLTK if you want to keep track of character offsets of sentences\n",
    "sents = sent_tokenize(report.replace('\\n',' ')) # removing new line breaks\n",
    "# Print out list of sentences:\n",
    "sent_count = 0\n",
    "for s in sents:\n",
    "    print(\"Sentence \" + str(sent_count) +\":\")\n",
    "    print(s)\n",
    "    print()\n",
    "    sent_count = sent_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkF7qKoXsX8I"
   },
   "outputs": [],
   "source": [
    "sent_count = 0\n",
    "for s_start, s_finish in PunktSentenceTokenizer().span_tokenize(report):\n",
    "    print(\"Sentence \" + str(sent_count) +\": \" + str([s_start, s_finish]))\n",
    "    print(report[s_start:s_finish].replace('\\n',' '))\n",
    "    print()\n",
    "    sent_count = sent_count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4XRba2RsX8Q"
   },
   "source": [
    "### Spot occurrence(s) of word(s) related to your concept in a sentence or document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8FOZQz7sX8T"
   },
   "outputs": [],
   "source": [
    "# Simple spotter: Spot occurrence of a term in a given lexicon anywhere within a text document or sentence:\n",
    "def spotter(text, lexicon):\n",
    "    text = text.lower()\n",
    "    # Spot if a document mentions any of the terms in the lexicon (not worrying about negation detection yet)\n",
    "    match = [x in text for x in lexicon]\n",
    "    if any(match) == True:\n",
    "        mentioned = 1\n",
    "    else:\n",
    "        mentioned = 0\n",
    "    return mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2klc13vsX8b"
   },
   "outputs": [],
   "source": [
    "# Where the lexicon is a list of word(s) or phrase(s) refering to a concept of interest to you, e.g.\n",
    "ptx = ['pneumothorax', 'ptx']\n",
    "sent1 = 'Large left apical ptx present.'\n",
    "sent2 = 'Hello world for NLP'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrGoOz2rsX8q"
   },
   "outputs": [],
   "source": [
    "# lexicon mentioned in text, spotter return 1 (yes)\n",
    "spotter(sent1, ptx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mv8L6YgJsX8z"
   },
   "outputs": [],
   "source": [
    "# lexicon not mentioned in text, spotter return 0 (no)\n",
    "spotter(sent2, ptx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjY1RsVxsX87"
   },
   "source": [
    "**How can we do better?**\n",
    "We can do the spotting of concepts (lexicons) A LOT better (more sensitive) if we curate a list of all the ways that the concept could be expressed in raw text. This is what the NLP tool can help you achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdGA0_RCsX88"
   },
   "source": [
    "### Download a lexicon from the NLP tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxCveXnLsX8_"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "# Enter your team's username between the quotation marks:\n",
    "user = \"team?\"\n",
    "# Enter your team's password\n",
    "#password = getpass.getpass()\n",
    "# If the above doesn't work, then comment out the password variable above and hard code your team's password below:\n",
    "password = '(your teams password)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k0DikGGAsX9G"
   },
   "outputs": [],
   "source": [
    "# This is the id of the lexicon - you can see it in the URL line when you are working with the lexicon\n",
    "# For example, for pneumothorax, it is:\n",
    "oid = \".2.48\"\n",
    "# You can do this in a loop to download all relevant lexicons into a data format you prefer too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urOKwOq8sX9M"
   },
   "outputs": [],
   "source": [
    "# Don't spam with insecure warnings - some machines do not have all signing authority\n",
    "# root certificates preinstalled\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttoSeI6VsX9R"
   },
   "outputs": [],
   "source": [
    "# The endpoints for the REST\n",
    "host = \"https://dla.sl.res.ibm.com\"\n",
    "lexurl = host + \"/oid\" + oid.replace('.', '/')\n",
    "quartermaster =  host + \"/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8K_mXhCsX9Y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up auth and get the lexicon. Then pull the terms out and lower case them\n",
    "auth=(user,password)\n",
    "lex = requests.get(lexurl, verify=False, auth=auth).json()\n",
    "terms = list(map(lambda x: x[\"surfaceForm\"].lower(), lex[\"members\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "U0b-NKqesX9g",
    "outputId": "d21fbc07-fb1d-44fe-a1c2-8d63f033cec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pneumothorax', 'ptx', 'pneumothoraces', 'pnuemothorax', 'pnumothorax', 'pntx', 'penumothorax', 'pneomothorax', 'pneumonthorax', 'pnemothorax', 'pneumothoraxes', 'pneumpthorax', 'pneuomthorax', 'pneumothorx', 'pneumothrax', 'pneumothroax', 'pneumothraces', 'pneunothorax', 'enlarging pneumo', 'pneumothoroax', 'pneuothorax']\n"
     ]
    }
   ],
   "source": [
    "# Printing out the pneumothorax lexicon (after 5 minutes of curating work on the NLP tool)\n",
    "ptx = terms.copy()\n",
    "print(ptx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "te2F6evWsX9u"
   },
   "source": [
    "### Negation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4WUjy4LsX9w"
   },
   "outputs": [],
   "source": [
    "# But it's not enough to just spot word occurrences to determine if a concept is affirmative (positive/present) or not.\n",
    "\n",
    "# e.g. lexicon mentioned in text but negated, a simple spotter would still return 1 (yes)\n",
    "sent3 = 'Pneumothorax has resolved.'\n",
    "spotter(sent3, ptx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdD6dxLMsX99"
   },
   "outputs": [],
   "source": [
    "# However, if negation related words occur in close proximity (e.g. same sentence) to a spotted concept \n",
    "# Then we can right some rules to determine if the concept was negated or not\n",
    "\n",
    "# e.g. spotting negation words in the same sentence:\n",
    "neg = ['no','never','not','removed', 'ruled out', 'resolved']\n",
    "spotter(sent3, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TIf0l1nmsX-G"
   },
   "source": [
    "### Using off-the-shelf python library for negation, e.g. Negex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "weCXERm6yjGp"
   },
   "outputs": [],
   "source": [
    "#This downloads a copy of negex.py and negex_triggers.txt into this environment, we will learn how to use this in the next block\n",
    "!wget  https://stuff.mit.edu/~cwc76/hst953/negex.py\n",
    "!wget  https://stuff.mit.edu/~cwc76/hst953/negex_triggers.txt\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lH7ofx7csX-J"
   },
   "outputs": [],
   "source": [
    "import negex\n",
    "rfile = open(r'negex_triggers.txt')\n",
    "irules = negex.sortRules(rfile.readlines())\n",
    "rfile.close()\n",
    "\n",
    "# Example:\n",
    "sent = \"There is no evidence of ptx.\"\n",
    "ptx = ['pneumothorax', 'ptx']\n",
    "tagger = negex.negTagger(sentence = sent, phrases = ptx, rules = irules, negP=False)\n",
    "negation = tagger.getNegationFlag()\n",
    "negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4SH4MWFsX-O"
   },
   "outputs": [],
   "source": [
    "# Applying Negex to the first note:\n",
    "# Specify the lexicon of interest (\"phrases\" for Negex)\n",
    "ptx = terms.copy()\n",
    "# Get a randome note from the dataset:\n",
    "note = CXRreports['text'][random.randint(0,1000)]\n",
    "# Tokenize the sentences:\n",
    "sents = sent_tokenize(note.replace('\\n',' ')) # replacing new line breaks\n",
    "# Applying spotter function to each sentence:\n",
    "#neg_output = []\n",
    "count = 0\n",
    "for sent in sents:\n",
    "    # Apply Negex if a term in the ptx lexicon is spotted\n",
    "    if spotter(sent,ptx) == 1:\n",
    "        tagger = negex.negTagger(sentence = sent, phrases = ptx, rules = irules, negP=False)\n",
    "        negation = tagger.getNegationFlag()\n",
    "        #neg_output.append(negation)\n",
    "        print(\"Sentence \" + str(count) + \":\\n\" + sent + \"\\nNegex output: \" + negation + '\\n')\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLsQFv0qsX-U"
   },
   "outputs": [],
   "source": [
    "# Show the relevant CXR report for the analysis\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTK33byysX-a"
   },
   "source": [
    "### Exercise for you:\n",
    "\n",
    "You can use similar/improved pipeline to loop through all the notes in your dataset and through different concepts/lexicons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMg45S-HsX-c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XTrozTq7sX-o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqJmlOkAsX-s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZwZ6kV-sX-v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of MIT Tutorial - Part - C - Pneumothorax.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
