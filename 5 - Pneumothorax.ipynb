{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5 - Pneumothorax.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christinium/NZ-workshop/blob/master/5%20-%20Pneumothorax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kahC0Hi6sX7a"
      },
      "cell_type": "markdown",
      "source": [
        "# Pneumothorax example\n",
        "\n",
        "## Sentence tokenization, and spotting term + negation\n",
        "\n",
        "This example spots meantions of the \"pneumothorax\" lexicon in CXR reports and looks at whether the spotted pneumothorax mentioned was negated or not. \n",
        "\n",
        "Originally contributed by:\n",
        "\n",
        "*Joy Wu* <joy.wu@ibm.com>*, *Daniel Gruhl <dgruhl@us.ibm.com>*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IghAvd9KsX7g",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Required files\n",
        "import requests\n",
        "from requests.auth import HTTPBasicAuth\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eItuw11H61V2"
      },
      "cell_type": "markdown",
      "source": [
        "**Authenticate:** The line of code below ensures you are an authenticated user accessing the MIMIC database. You will need to rerun this each time you open the notebook."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H30PHyTf2m0I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user() #This will allow you to authenticate access to BigQuery"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sRzpINxx7BJY"
      },
      "cell_type": "markdown",
      "source": [
        "**Query Function: **This is a method that executes a desired SQL query on the database. If you want to run a query, you can use the function name below, which we named run_query()\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k7Y86QrA2xDy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_id='new-zealand-2018-datathon'\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"]=project_id\n",
        "# Read data from BigQuery into pandas dataframes.\n",
        "def run_query(query):\n",
        "  return pd.io.gbq.read_gbq(query, project_id=project_id, verbose=False, configuration={'query':{'useLegacySql': False}})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "72KosSwasX7p"
      },
      "cell_type": "markdown",
      "source": [
        "### Sentence splitting:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2oVmqJuLsX7s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read the sample CXR reports \n",
        "\n",
        "CXRreports = run_query('''\n",
        "SELECT * \n",
        "FROM `nlp_demo.radiology`\n",
        "''')\n",
        "CXRreports.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "39aeASmGsX75",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This prints the first report (numbering starts at 0). You can change the report by changing \"0\" to another number\n",
        "report = CXRreports.text[0]\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1XE_GBgB4f6w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  #This imports nltk and punkt into our environment\n",
        "  >>> import nltk\n",
        "  >>> nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G7iMxWsUsX8B",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tokenize the sentences with sent_tokenize from NLTK\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "# Alternatively, tokenize with PunktSentenceTokenizer from NLTK if you want to keep track of character offsets of sentences\n",
        "sents = sent_tokenize(report.replace('\\n',' ')) # removing new line breaks\n",
        "# Print out list of sentences:\n",
        "sent_count = 0\n",
        "for s in sents:\n",
        "    print(\"Sentence \" + str(sent_count) +\":\")\n",
        "    print(s)\n",
        "    print()\n",
        "    sent_count = sent_count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xkF7qKoXsX8I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_count = 0\n",
        "for s_start, s_finish in PunktSentenceTokenizer().span_tokenize(report):\n",
        "    print(\"Sentence \" + str(sent_count) +\": \" + str([s_start, s_finish]))\n",
        "    print(report[s_start:s_finish].replace('\\n',' '))\n",
        "    print()\n",
        "    sent_count = sent_count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "I4XRba2RsX8Q"
      },
      "cell_type": "markdown",
      "source": [
        "### Spot occurrence(s) of word(s) related to your concept in a sentence or document"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t8FOZQz7sX8T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Simple spotter: Spot occurrence of a term in a given lexicon anywhere within a text document or sentence:\n",
        "def spotter(text, lexicon):\n",
        "    text = text.lower()\n",
        "    # Spot if a document mentions any of the terms in the lexicon (not worrying about negation detection yet)\n",
        "    match = [x in text for x in lexicon]\n",
        "    if any(match) == True:\n",
        "        mentioned = 1\n",
        "    else:\n",
        "        mentioned = 0\n",
        "    return mentioned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "j2klc13vsX8b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Where the lexicon is a list of word(s) or phrase(s) refering to a concept of interest to you, e.g.\n",
        "ptx = ['pneumothorax', 'ptx']\n",
        "sent1 = 'Large left apical ptx present.'\n",
        "sent2 = 'Hello world for NLP'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RrGoOz2rsX8q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# lexicon mentioned in text, spotter return 1 (yes)\n",
        "spotter(sent1, ptx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mv8L6YgJsX8z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# lexicon not mentioned in text, spotter return 0 (no)\n",
        "spotter(sent2, ptx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DjY1RsVxsX87"
      },
      "cell_type": "markdown",
      "source": [
        "**How can we do better?**\n",
        "We can do the spotting of concepts (lexicons) A LOT better (more sensitive) if we curate a list of all the ways that the concept could be expressed in raw text. This is what the NLP tool can help you achieve."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jdGA0_RCsX88"
      },
      "cell_type": "markdown",
      "source": [
        "### Lexicons - there are tools out there where you can get lexicons.  Using an IBM one, we have a list of terms listed below"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "U0b-NKqesX9g",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Printing out the pneumothorax lexicon (after 5 minutes of curating work on the NLP tool)\n",
        "ptx = ['pneumothorax', 'ptx', 'pneumothoraces', 'pnuemothorax', 'pnumothorax', 'pntx', 'penumothorax', 'pneomothorax', 'pneumonthorax', 'pnemothorax', 'pneumothoraxes', 'pneumpthorax', 'pneuomthorax', 'pneumothorx', 'pneumothrax', 'pneumothroax', 'pneumothraces', 'pneunothorax', 'enlarging pneumo', 'pneumothoroax', 'pneuothorax']\n",
        "print(ptx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "te2F6evWsX9u"
      },
      "cell_type": "markdown",
      "source": [
        "### Negation detection"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F4WUjy4LsX9w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# But it's not enough to just spot word occurrences to determine if a concept is affirmative (positive/present) or not.\n",
        "\n",
        "# e.g. lexicon mentioned in text but negated, a simple spotter would still return 1 (yes)\n",
        "sent3 = 'Pneumothorax has resolved.'\n",
        "spotter(sent3, ptx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gdD6dxLMsX99",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# However, if negation related words occur in close proximity (e.g. same sentence) to a spotted concept \n",
        "# Then we can right some rules to determine if the concept was negated or not\n",
        "\n",
        "# e.g. spotting negation words in the same sentence:\n",
        "neg = ['no','never','not','removed', 'ruled out', 'resolved']\n",
        "spotter(sent3, neg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TIf0l1nmsX-G"
      },
      "cell_type": "markdown",
      "source": [
        "### Using off-the-shelf python library for negation, e.g. Negex"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "weCXERm6yjGp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This downloads a copy of negex.py and negex_triggers.txt into this environment, we will learn how to use this in the next block\n",
        "!wget  https://stuff.mit.edu/~cwc76/hst953/negex.py\n",
        "!wget  https://stuff.mit.edu/~cwc76/hst953/negex_triggers.txt\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lH7ofx7csX-J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import negex\n",
        "rfile = open(r'negex_triggers.txt')\n",
        "irules = negex.sortRules(rfile.readlines())\n",
        "rfile.close()\n",
        "\n",
        "# Example:\n",
        "sent = \"There is no evidence of ptx.\"\n",
        "ptx = ['pneumothorax', 'ptx']\n",
        "tagger = negex.negTagger(sentence = sent, phrases = ptx, rules = irules, negP=False)\n",
        "negation = tagger.getNegationFlag()\n",
        "negation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c4SH4MWFsX-O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Applying Negex to the first note:\n",
        "note = CXRreports['text'][16]\n",
        "# Tokenize the sentences:\n",
        "sents_blob = sent_tokenize(note.replace('\\n',' ')) # replacing new line breaks with a space, splits into sentences\n",
        "# Applying spotter function to each sentence:\n",
        "#neg_output = []\n",
        "count = 0\n",
        "for sent in sents:\n",
        "    # Apply Negex if a term in the ptx lexicon is spotted\n",
        "    if spotter(sent,ptx) == 1:\n",
        "        tagger = negex.negTagger(sentence = sent, phrases = ptx, rules = irules, negP=False)\n",
        "        negation = tagger.getNegationFlag()\n",
        "        #neg_output.append(negation)\n",
        "        print(\"Sentence \" + str(count) + \":\\n\" + sent + \"\\nNegex output: \" + negation + '\\n')\n",
        "        count = count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CLsQFv0qsX-U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Show the relevant CXR report for the analysis\n",
        "print(note)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jTK33byysX-a"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise for you:\n",
        "\n",
        "You can use similar/improved pipeline to loop through all the notes in your dataset and through different concepts/lexicons!"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cMg45S-HsX-c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XTrozTq7sX-o",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vqJmlOkAsX-s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IZwZ6kV-sX-v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}